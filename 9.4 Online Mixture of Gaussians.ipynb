{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please consult the end of chapter 9.4 of _Pattern Recognition and Machine Learning_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivation for Online Mixture of Gaussians\n",
    "\n",
    "Online algorithms consider a single data point at a time rather than an entire batch. Online could also be called \"incremental.\" \n",
    "\n",
    "When applying Expectation Maximization to a gaussian mixture given large amounts of data, the batch method's calculation time depends on the number of data points. In the online formulation, the Expectation and Maximization steps both take fixed time since they operate on only a single data point. This can provide a significant performance boost when you don't need to consider the entire batch of data every iteration.\n",
    "\n",
    "In the online formulation of Mixture of Gaussians, the parameters are updated incrementally. That means the algorithm can converge more quickly than a batch approach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-04-24T09:22:21.020401Z",
     "start_time": "2018-04-24T09:22:21.015881Z"
    }
   },
   "source": [
    "# Derivation of Online Gaussian Mixture\n",
    "\n",
    "We derive 9.78 & 9.79 in the text. The purpose is to define an incremental update step to the mean of a gaussian. We start from 9.18, the definition of the mean.\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathbf{\\mu}_k &= \\frac{1}{N_k} \\sum_{n=1}^{N} \\gamma(z_{nk}) \\mathbf{x}_n \\\\\n",
    "    N_k &= \\sum_{n=1}^{N} \\gamma(z_{nk})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating N\n",
    "We will consider an update technique where we recompute the responsibilities for a single data point, $\\mathbf{x}_m$. We initialize by using our definition from above.\n",
    "\n",
    "\\begin{align}\n",
    "    N_{k}^{old} &= \\sum_{n} \\gamma^{old}(z_{nk}) \\\\\n",
    "    N_{k}^{new} &= \\sum_{n \\neq m} \\gamma^{old}(z_{nk}) + \\gamma^{new}(z_{mk})\n",
    "\\end{align}\n",
    "\n",
    "We can use these results, subtitute $N_{k}^{old}$ into the ladder equation to retrieve 9.79. (Subtract out when $m = n$ to convert $N_{k}^{old}$ to the sum in the ladder equation.)\n",
    "\n",
    "\\begin{equation}\n",
    "    N_{k}^{new} = N_{k}^{old} + \\gamma^{new}(z_{mk}) - \\gamma^{old}(z_{mk})\n",
    "\\end{equation}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the mean\n",
    "Now, let us derive the mean update. We use a similar update technique.\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathbf{\\mu}_k^{old} &= \\frac{1}{N_k^{old}} \\sum_{n=1}^{N} \\gamma^{old} (z_{nk}) \\mathbf{x}_n\n",
    "\\end{align}\n",
    "\n",
    "Now we recompute the responsibilities, $\\gamma(z_{mk})$, from a single point.\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathbf{\\mu}_k^{new} &= \\frac{1}{N_k^{new}} \\Big(\n",
    "                            \\sum_{n \\neq m} \\gamma^{old}(z_{nk}) \\mathbf{x}_n + \\gamma^{new}(z_{mk}) \\mathbf{x}_m \\Big) \\\\\n",
    "    &= \\frac{1}{N_k^{new}}\n",
    "        \\Big( N_k^{old} \\mathbf{\\mu}_k^{old} - \\gamma^{old}(z_{mk}) \\mathbf{x}_m + \\gamma^{new}(z_{mk}) \\mathbf{x}_m \\Big) \\\\\n",
    "    &= \\frac{1}{N_k^{new}}\n",
    "        \\Big( \\big ( N_{k}^{new} - \\gamma^{new}(z_{mk}) + \\gamma^{old}(z_{mk}) \\big ) \\mathbf{\\mu}_k^{old} - \\gamma^{old}(z_{mk}) \\mathbf{x}_m + \\gamma^{new}(z_{mk}) \\mathbf{x}_m \\Big) \\\\\n",
    "    &= \\mathbf{\\mu}_k^{old} + \n",
    "        \\Big( \\frac{\\gamma^{new}(z_{mk}) - \\gamma^{old}(z_{mk})}{N_{k}^{new}} \\Big)\n",
    "        (\\mathbf{x}_m - \\mathbf{\\mu}_k^{old})\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the covariances\n",
    "\n",
    "Similar update but for covariances\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathbf{\\Sigma}_k^{old} &= \\frac{1}{N_k^{old}} \\sum_{n} \\gamma^{old} (z_{nk}) (\\mathbf{x}_n - \\mathbf{\\mu}_k^{old})\n",
    "        (\\mathbf{x}_n - \\mathbf{\\mu}_k^{old})^{T}\n",
    "\\end{align}\n",
    "\n",
    "Now we recompute the responsibilities, $\\gamma(z_{mk})$, from a single point.\n",
    "\n",
    "\\begin{align}\n",
    "    \\mathbf{\\Sigma}_k^{new} &= \\frac{1}{N_k^{new}} \\sum_{n \\neq m} \\Big(\n",
    "        \\gamma^{new} (z_{nk}) (\\mathbf{x}_n - \\mathbf{\\mu}_k^{new}) (\\mathbf{x}_n - \\mathbf{\\mu}_k^{new})^{T} \\Big) \\\\\n",
    "    &= \\frac{1}{N_k^{new}} \\sum_{n \\neq m} \\Big(\n",
    "        \\gamma^{old} (z_{nk}) (\\mathbf{x}_n - \\mathbf{\\mu}_k^{new}) (\\mathbf{x}_n - \\mathbf{\\mu}_k^{new})^{T} +\n",
    "        \\gamma^{new} (z_{mk}) (\\mathbf{x}_m - \\mathbf{\\mu}_k^{new}) (\\mathbf{x}_m - \\mathbf{\\mu}_k^{new})^{T} \\Big) \\\\\n",
    "\\end{align}\n",
    "\n",
    "For space, define \n",
    "\n",
    "\\begin{align}\n",
    "    \\mathbf{A} &= \\sum_{n} (\\mathbf{x}_n - \\mathbf{\\mu}_k^{new}) (\\mathbf{x}_n - \\mathbf{\\mu}_k^{new})^{T} \\\\\n",
    "    \\mathbf{B} &= (\\mathbf{x}_m - \\mathbf{\\mu}_k^{new}) (\\mathbf{x}_m - \\mathbf{\\mu}_k^{new})^{T}\n",
    "\\end{align}\n",
    "\n",
    "\\begin{align}\n",
    "    &= \\frac{1}{N_k^{new}} \\Big(\n",
    "        N_k^{old} \\mathbf{A} -\n",
    "        \\gamma^{old} (z_{mk}) \\mathbf{B} +\n",
    "        \\gamma^{new} (z_{mk}) \\mathbf{B} \\Big) \\\\\n",
    "    &= \\frac{1}{N_k^{new}} \\Big(\n",
    "        \\big( N_{k}^{new} - \\gamma^{new}(z_{mk}) + \\gamma^{old}(z_{mk}) \\big) \\mathbf{A} -\n",
    "        \\gamma^{old} (z_{mk}) \\mathbf{B} +\n",
    "        \\gamma^{new} (z_{mk}) \\mathbf{B} \\Big) \\\\\n",
    "    &= \\mathbf{A} + \n",
    "        \\Big( \\frac{\\gamma^{new}(z_{mk}) - \\gamma^{old}(z_{mk})}{N_{k}^{new}} \\Big)\n",
    "        (\\mathbf{x}_m - \\mathbf{\\mu}_k^{new}) \\mathbf{B}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Updating the mixing coefficients\n",
    "\n",
    "Update for mixing coefficients. $\\pi_{k} = \\frac{N_{k}}{N}$.\n",
    "\n",
    "\\begin{equation}\n",
    "    \\pi_{k}^{old} = \\frac{N_{k}^{old}}{N}\n",
    "\\end{equation}\n",
    "\n",
    "Update the responsibilities...\n",
    "\n",
    "\\begin{align}\n",
    "    \\pi_{k}^{new} &= \\frac{N_{k}^{new}}{N} \\\\\n",
    "        &= \\frac{1}{N} \\sum_{n \\neq m} \\gamma^{old}(z_{nk}) + \\gamma^{new}(z_{mk}) \\\\\n",
    "        &= \\frac{1}{N} \\Big( N_{k}^{old} + \\gamma^{new}(z_{mk}) - \\gamma^{old}(z_{mk}) \\Big)\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algorithm for Online Gaussian Mixture\n",
    "\n",
    "1. As usual, initalize the means $\\mathbf{\\mu}_k$, covariances $\\Sigma_k$, and mixing coefifients $\\pi_k$, and evaluate the inital value of the log likelihood.\n",
    "2. **E0 Step** Evaluate the responsibilities for every data point so that we have a baseline.\n",
    "3. **E Step** Evaluate the new responsibility \n",
    "4. ... Problem here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "start_time": "2018-04-25T20:37:59.820Z"
    }
   },
   "source": [
    "# Sources:\n",
    "    - Bishop - Pattern Recognition And Machine Learning - Springer  2006 - Chapter 9.2\n",
    "    - The Matrix Cookbook: http://www2.imm.dtu.dk/pubdb/views/edoc_download.php/3274/pdf/imm3274.pdf\n",
    "    - https://math.stackexchange.com/questions/195911/covariance-of-gaussian-mixtures"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
